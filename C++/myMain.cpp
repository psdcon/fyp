// Opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
// C
#include <stdio.h>
// C++
#include <iostream>
#include <sstream>
using namespace cv;
using namespace std;

const int QUITLOOP = -1;

// Global variables
VideoCapture capture;
Mat frame; // Current frame
Mat fgMaskMOG2; // fg mask generated by MOG2 method
Mat fgMaskKNN;
Mat backgroundModelMOG2;
Mat backgroundModelKNN;
Mat biggestSegment;
Mat fgMaskMOG2ED;
Mat fgMaskKNNED;

Ptr<BackgroundSubtractorMOG2> pMOG2; // MOG2 Background subtractor
Ptr<BackgroundSubtractorKNN> pKNN; // KNN Background subtractor

double scalingFactor = 0.75;
int w = 640 * scalingFactor;
int h = 360 * scalingFactor;
Mat MOG2Images(h*3, w, CV_8UC3);
Mat KNNImages(h*3, w, CV_8UC3);
Mat temp;
Mat finerMask;


// Array of Centroids
vector<Point> pts;

int waitTime = 50;
int x = 0, y = 0;
int startFrame = 80;
int trampolineTop=240;

// Keyboard vars
bool paused = false;
bool track = true;
bool showBgMasks = false;

// Prototypes
void doErodeDilate(Mat &input, Mat &output);
int keyboardShortcuts();
void drawFrameNumber(Mat& img);
void trackFilteredObject(int &x, int &y, Mat mask, Mat &img);
void detectLines(cv::Mat src);
static void refineSegments(const Mat& img, Mat& mask, Mat& dst, int &x, int &y);
void drawBoundingBox(int x, int y, Mat &img, Mat &mask);

// Main function. Sets up vars and runs video process
int main(int argc, char* argv[]) {

    string vidPath = "C:\\Users\\psdco\\Videos\\take1 640x360.mp4";

    // Open a capture object
    capture.open(vidPath);
    if (!capture.isOpened()) {
        // Error in opening the video input
        cerr << "Unable to open video file: " << vidPath << endl;
        exit(EXIT_FAILURE);
    }
	capture.set(CV_CAP_PROP_POS_FRAMES, startFrame);

    // Create GUI windows
    namedWindow("Frame");

	// Create mask for walls
	Mat maskAllButCentre = Mat::zeros(capture.get(CV_CAP_PROP_FRAME_HEIGHT), capture.get(CV_CAP_PROP_FRAME_WIDTH), CV_8U); // all 0
	maskAllButCentre(Rect(capture.get(CV_CAP_PROP_FRAME_WIDTH)*0.25, 0, capture.get(CV_CAP_PROP_FRAME_WIDTH)*0.5, capture.get(CV_CAP_PROP_FRAME_HEIGHT)*0.9)) = 255;
	//imshow("maskAllButCentre", maskAllButCentre);

    // Create Background Subtractor objects
    pMOG2 = createBackgroundSubtractorMOG2(); // MOG2
	pMOG2->setShadowValue(0); // default 127. set to black
	pKNN = createBackgroundSubtractorKNN();
	pKNN->setShadowValue(0); // default 127. set to black

    cout << "Starting video" << endl;
    // Loop for all frames
    while( 1 ) {

        // Read the current frame
        if (!capture.read(frame)) {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            exit(EXIT_FAILURE);
        }
        // detectLines(frame);

        // Update the background model
        pMOG2->apply(frame, fgMaskMOG2);
        // imshow("MOG2 Fg Mask", fgMaskMOG2);
        resize(fgMaskMOG2, temp, Size(), scalingFactor, scalingFactor);
        cvtColor(temp, temp, CV_GRAY2RGB);
        temp.copyTo( MOG2Images( Rect(0, h, w, h) ) );
        // Show Background Model
        pMOG2->getBackgroundImage(backgroundModelMOG2);
        // imshow("MOG2 Bg Model", backgroundModelMOG2);
        resize(backgroundModelMOG2, temp, Size(), scalingFactor, scalingFactor);
        temp.copyTo( MOG2Images( Rect(0, 0, w, h) ) );
        // Mask to isolate trampoline
        fgMaskMOG2 = fgMaskMOG2 & maskAllButCentre;


        // KNN Background Subtraction
        pKNN->apply(frame, fgMaskKNN);
		// imshow("KNN Fg Mask", fgMaskKNN);
        resize(fgMaskKNN, temp, Size(), scalingFactor, scalingFactor);
        cvtColor(temp, temp, CV_GRAY2RGB);
        temp.copyTo( KNNImages( Rect(0, h, w, h) ) );
        // Show Background Model
        pKNN->getBackgroundImage(backgroundModelKNN);
        // imshow("KNN Bg Model", backgroundModelKNN);
        resize(backgroundModelKNN, temp, Size(), scalingFactor, scalingFactor);
        temp.copyTo( KNNImages( Rect(0, 0, w, h) ) );
		// Mask to isolate trampoline
		fgMaskKNN = fgMaskKNN & maskAllButCentre;


        // Clean up background masks
        doErodeDilate(fgMaskKNN, fgMaskKNNED);
        // imshow("KNN Fg Erode Dilated", fgMaskKNNED);
        resize(fgMaskKNNED, temp, Size(), scalingFactor, scalingFactor);
        cvtColor(temp, temp, CV_GRAY2RGB);
        temp.copyTo( KNNImages( Rect(0, h*2, w, h) ) );

        doErodeDilate(fgMaskMOG2, fgMaskMOG2ED);
        // imshow("MOG2 Fg Erode Dilated", fgMaskMOG2ED);
        resize(fgMaskMOG2ED, temp, Size(), scalingFactor, scalingFactor);
        cvtColor(temp, temp, CV_GRAY2RGB);
        temp.copyTo( MOG2Images( Rect(0, h*2, w, h) ) );


        imshow("MOG2 Bg Model, Fg Mask, Cleaned", MOG2Images);
        imshow("KNN Bg Model, Fg Mask, Cleaned", KNNImages);


        // Find the biggest contour
		refineSegments(frame, fgMaskKNNED, biggestSegment, x, y);
		imshow("Biggest Segment", biggestSegment);

        // Make small bounding box window and add x, y.
        finerMask = fgMaskKNN;
        fgMaskKNN.copyTo(finerMask, biggestSegment);
		if (track){
			drawBoundingBox(x, y, frame, finerMask);
        }
        else {
            destroyWindow("Tracking...");
        }

        // Draw frame number
        drawFrameNumber(frame);

        // Show the current frame and the fg masks
        imshow("Frame", frame);
        // imshow("Frame", maskedFrame);

        // Do keyboard controls
        if (keyboardShortcuts() == QUITLOOP)
            break;

        // Loop video when it gets to the end
        if (capture.get(CV_CAP_PROP_POS_FRAMES) == capture.get(CV_CAP_PROP_FRAME_COUNT)) {
            capture.set(CV_CAP_PROP_POS_FRAMES, startFrame);
        }
    }

    capture.release();

    // Destroy GUI windows
    destroyAllWindows();
    return EXIT_SUCCESS;
}

void doErodeDilate(Mat &input, Mat &output) {

    //dilate(mask, temp, Mat(), Point(-1,-1), 1); / if uncommenting, don't forget to change mask in erode
    erode(input, output, Mat(), Point(-1,-1), 1);
    dilate(output, output, Mat(), Point(-1, -1), 3);

 //    // https:// Www.youtube.com/watch?v=bSeFrPrqZ2A
 //    Mat erodeElement = getStructuringElement(MORPH_RECT, Size(2, 2));
 //    // imshow("erodeElement", erodeElement);

 //    // Dilate with larger element so make sure object is nicely visible
 //    Mat dilateElement = getStructuringElement(MORPH_RECT, Size(6, 6));
 //    // imshow("dilateElement", dilateElement);

	// Mat erodeDilate;
 //    erode(original, erodeDilate, erodeElement);
 //    erode(erodeDilate, erodeDilate, erodeElement);

 //    // Increase the size of the main objects
 //    dilate(erodeDilate, erodeDilate, dilateElement);
 //    dilate(erodeDilate, erodeDilate, dilateElement);
}

//http://docs.opencv.org/3.1.0/dd/d9d/segment_objects_8cpp-example.html#a20
static void refineSegments(const Mat& img, Mat& mask, Mat& dst, int &x, int &y) {
    int niters = 3;
    vector<vector<Point>> contours;
    vector<Vec4i> hierarchy;


    findContours( mask, contours, hierarchy, RETR_CCOMP, CHAIN_APPROX_SIMPLE );

    dst = Mat::zeros(img.size(), CV_8UC3);

    if( contours.size() == 0 )
        return;

    // iterate through all the top-level contours,
    // draw each connected component with its own random colour
    int idx = 0, largestComp = 0;
    double maxArea = 0;

    for( ; idx >= 0; idx = hierarchy[idx][0] )
    {
        const vector<Point>& c = contours[idx];
        double area = fabs(contourArea(Mat(c)));
        if( area > maxArea )
        {
            maxArea = area;
            largestComp = idx;
        }
    }
    Scalar color( 255, 255, 255 );
    drawContours( dst, contours, largestComp, color, FILLED, LINE_8, hierarchy );
	cvtColor(dst, dst, CV_RGB2GRAY);

    // Draw a bounding box
    Moments moment = moments((Mat)contours[largestComp]);
    double area = moment.m00;

    int prevX = x;
    int prevY = y;

    x = (int)(moment.m10 / area);
    y = (int)(moment.m01 / area);

    // Don't track below trampoline
    if (y > trampolineTop){
        x = prevX;
        y = prevY;
        // y = trampolineTop;
    }
}

int keyboardShortcuts() {
    int keyboard = waitKey(waitTime);

    if (keyboard == 'q' || keyboard == 27){ // 'Esc' or 'q' key has been pressed, exit program.
        cout << "Quitting..." << endl;
		return QUITLOOP;
    }
	else if (keyboard == 't') {
		track = !track;
		cout << "Tracking toggled " << waitTime << endl;
	}
    // > Speed up program by decreasing wait time
    else if (keyboard == '.'){
        waitTime -= 5;
        // Set minimum of 10ms
        waitTime = (waitTime < 5)? 5: waitTime;
        cout << "Speeding up by changing wait to " << waitTime << endl;
    }
    // < Sow down program by increasing wait time
    else if (keyboard == ','){
        waitTime += 5;
        cout << "Slowing down by changing wait to " << waitTime << endl;
    }
    // / Reset wait time
    else if (keyboard == '/'){
        waitTime = 25;
        cout << "Speed reset to " << waitTime << endl;
    }

    else if (keyboard == 'k' || paused){ // 'k' has been pressed. this will pause/resume the code.
        if (paused) {
            cout << "Code paused, press 'k' again to resume" << endl;
            // While paused, different keyboard shortcuts
            while (paused) {
                double desiredFrame = 0;
                keyboard = waitKey();
                if (keyboard == 'j') {
                    // Go to previous frame
                    desiredFrame = capture.get(CV_CAP_PROP_POS_FRAMES) - 2;
                    desiredFrame = (desiredFrame < 0)? desiredFrame+capture.get(CV_CAP_PROP_FRAME_COUNT): desiredFrame; // make sure haven't rolled over 0 to -1

                    capture.set(CV_CAP_PROP_POS_FRAMES, desiredFrame);
                    cout  << "Previous frame" << endl;
                    break;
                }
                else if (keyboard == 'k') {
                    // Resume video
                    paused = false;
                    cout  << "Code Resumed" << endl;
                    break;
                }
                else if (keyboard == 'l') {
                    // Show next frame by allowing code to continue around
                    cout  << "Next Frame" << endl;
                    break;
                }
                else if (keyboard == 'q' || keyboard == 27){ // 'Esc' or 'q' key has been pressed, exit program.
                    cout << "Quitting..." << endl;
					return QUITLOOP;
                }
            }
        }
        else {
            paused = true;
            cout << "Code was running, now it's paused" << endl;
        }
    }
    else if (keyboard >= '0' && keyboard <= '9'){
        // get number of frames at each deciPercentage and * by the percentage step
        double desiredFrame = (capture.get(CV_CAP_PROP_FRAME_COUNT)/10) * (keyboard-'0');
        capture.set(CV_CAP_PROP_POS_FRAMES, desiredFrame);
        cout << "Setting video to " << (keyboard-'0')*10 << "% through the video" << endl;
    }
    else {
        cout << "Detected keyboard press: " << keyboard;
    }

    return 0; // Do nothing (verses QUITLOOP)
}

void drawFrameNumber(Mat& img) {
    rectangle(img, cv::Point(10, 2), cv::Point(50, 20), cv::Scalar(255, 255, 255), -1);
    // Get the frame number and write it on the current frame
    stringstream ss;
    ss << capture.get(CAP_PROP_POS_FRAMES);
    string frameNumberString = ss.str();
    putText(img, frameNumberString.c_str(), cv::Point(15, 15), FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
}

void drawBoundingBox(int x, int y, Mat &img, Mat &mask) {

    // Crop to bounding box
    int width = 160;
    int height = 160;
    int top = x - width/2;
    int left = y - height/2;

    // Prevent from cropping off frame
    if (top < 0)
        top = 0;
    if (top + height/2 > capture.get(CV_CAP_PROP_FRAME_HEIGHT)) // bottom
        top = capture.get(CV_CAP_PROP_FRAME_HEIGHT) - height;
    if (left < 0)
        left = 0;
    if (left + width/2 > capture.get(CV_CAP_PROP_FRAME_WIDTH)) // right
        left = capture.get(CV_CAP_PROP_FRAME_WIDTH) - left;

    // Draw centre point
    circle(img, cv::Point(x, y), 1, cv::Scalar(0, 0, 255), 1);

    // Create me a window
    Mat meImages(height, width*3, CV_8UC3);
    Mat croppedImage = img(Rect(top, left, width, height));
    croppedImage.copyTo( meImages( Rect(0, 0, width, height) ) );

    Mat maskedFrame;
    img.copyTo(maskedFrame, mask);
    Mat croppedMaskedImage = maskedFrame(Rect(top, left, width, height));
    croppedMaskedImage.copyTo( meImages( Rect(width, 0, width, height) ) );

    Mat croppedCannyMaskedFrame;
    Canny(croppedImage, croppedCannyMaskedFrame, 50, 200, 3);
    cvtColor(croppedCannyMaskedFrame, croppedCannyMaskedFrame, CV_GRAY2BGR);
    croppedCannyMaskedFrame.copyTo( meImages( Rect(width*2, 0, width, height) ) );

    imshow("Tracking...", meImages);


    // Put center point coordiantes on screen
    putText(img, to_string(x) + " " + to_string(y), Point(0, 50), 1, 1, Scalar(0, 0, 255), 1);

    // Draw bounding box
    rectangle(img, cv::Point(x - 80, y - 80), cv::Point(x + 80, y + 80), cv::Scalar(0, 255, 0), 1);

    // imshow("Cropped colour", croppedImage);
}

RNG rng(12345);
const int MAX_NUM_OBJECTS = 50;
void trackFilteredObject(int &x, int &y, Mat mask, Mat &img) {

    // Find contours overwrites mask so use a temp
    Mat temp;
    mask.copyTo(temp);

    // These two vectors needed for output of findContours
    vector< vector<Point> > contours;
    vector<Vec4i> hierarchy;

    // Find contours of filtered image using openCV findContours function
    findContours(temp, contours, hierarchy, CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE);

    /// Draw contours
    // Mat drawing = Mat::zeros( mask.size(), CV_8UC3 );
    // for(int i = 0; i < contours.size(); i++) {
    //     //if (i == 5) break;
    //     Scalar color = Scalar( rng.uniform(0, 255), rng.uniform(0,255), rng.uniform(0,255) );
    //     drawContours( frame, contours, i, color, 2, 8, hierarchy, 0, Point() );
    // }

    // Use moments method to find our filtered object
    double refArea = 0;
    bool objectFound = false;

    if (hierarchy.size() > 0) {
        int numObjects = hierarchy.size();

        // If number of objects greater than MAX_NUM_OBJECTS we have a noisy filter
        if (numObjects < MAX_NUM_OBJECTS) {
            cout << endl;
            cout << numObjects << " objects found" << endl;
            for (int index = 0; index >= 0; index = hierarchy[index][0]) {

                Moments moment = moments((cv::Mat)contours[index]);
                double area = moment.m00;
                cout << "object " << index << " has area=" << area << endl;

                // If the area is less than 20 px by 20px then it is probably just noise
                // If the area is the same as the 3/2 of the image size, probably just a bad filter
                // We only want the object with the largest area so we safe a reference area each
                // Iteration and compare it to the area in the next iteration.
                if (area > 300  && area > refArea) {
                    x = (int)(moment.m10 / area);
                    y = (int)(moment.m01 / area);
                    objectFound = true;
                    refArea = area;
                    cout << "new refArea= " << refArea << endl;

                    Scalar color = Scalar( rng.uniform(0, 255), rng.uniform(0,255), rng.uniform(0,255) );
                    drawContours( img, contours, index, color, 2, 8, hierarchy, 0, Point() );
                    // rectangle(img, cv::Point(x, y), cv::Point(x+2, y+2), cv::Scalar(255, 255, 255), -1);
                }
            }

            // Let user know you found an object
            if (objectFound == true) {
                putText(img, "Tracking Object", Point(0, 50), 2, 1, Scalar(0, 255, 0), 1);
                // Draw object location on screen
                // drawObject(x, y, img);
                // rectangle(img,(384,0),(510,128),(0,255,0),3)
                rectangle(img, cv::Point(x-70, y-70), cv::Point(x+70, y+70), cv::Scalar(0, 255, 0), 1);
            }
        }
        else putText(img, "TOO MUCH NOISE! ADJUST FILTER", Point(0, 50), 1, 2, Scalar(0, 0, 255), 2);
    }
}

double findSlope(int x1, int y1, int x2, int y2);
double findDistance(int x1, int y1, int x2, int y2);
void detectLines(cv::Mat src) {
    Mat dst, cdst;
    Canny(src, dst, 50, 200, 3);
	cvtColor(dst, cdst, CV_GRAY2BGR);

    // Do probabilistic Hough transform.
    vector<Vec4i> lines;
    HoughLinesP( dst, lines, 1, CV_PI/180, 80, 30, 10 );

    cout.precision(2);

    // Filter lines based on slope
    vector<Vec4i> horizontalLines;
    for( size_t i = 0; i < lines.size(); i++ ) {
        Vec4i thisLine = lines[i];
        double slope = findSlope( thisLine[0], thisLine[1], thisLine[2], thisLine[3] );
        slope = fabs(slope);

        // cout << "line[" << i << "] x1="<<thisLine[0]<<" y1="<<thisLine[1]<<", x2="<<thisLine[2]<<" y2="<<thisLine[3]<<
        // fixed << " has slope=" << slope << endl;

        if (slope < 0.5){
            // line(cdst, Point(thisLine[0], thisLine[1]), Point(thisLine[2], thisLine[3]), Scalar(0,255,0), 1, 8 );
            horizontalLines.push_back(thisLine);
        }
    }

    // Filter to largest lines
    vector<Vec4i> longestHorzLines;
    for( size_t i = 0; i < horizontalLines.size(); i++ ) {
        Vec4i thisLine = horizontalLines[i];
        double distance = findDistance( thisLine[0], thisLine[1], thisLine[2], thisLine[3] );

        // cout << "line[" << i << "] x1="<<thisLine[0]<<" y1="<<thisLine[1]<<", x2="<<thisLine[2]<<" y2="<<thisLine[3]<<
        // fixed << " has distance=" << distance << endl;

        if (distance > 12){
            line(cdst, Point(thisLine[0], thisLine[1]), Point(thisLine[2], thisLine[3]), Scalar(0,255,0), 1, 8 );
            longestHorzLines.push_back(thisLine);
        }
    }

    // Find line closest to the center of the image
    double minValue = 999;
    int minIndex = 0;
    for( size_t i = 0; i < longestHorzLines.size(); i++ ) {
        Vec4i thisLine = longestHorzLines[i];
        double videoCenterx = capture.get(CV_CAP_PROP_FRAME_WIDTH)/2;
        double videoCentery = capture.get(CV_CAP_PROP_FRAME_HEIGHT)/2;

        double lineCenterx = (thisLine[2] + thisLine[0]) / 2;
        double lineCentery = (thisLine[3] + thisLine[1]) / 2;

        double distance2center = findDistance( videoCenterx, lineCenterx, videoCentery, lineCentery);

        if (distance2center < minValue){
            minValue = distance2center;
            minIndex = i;
        }
    }

    int x1 = 0;
    int y1 = longestHorzLines[minIndex][1];
    int x2 = capture.get(CV_CAP_PROP_FRAME_WIDTH);
    int y2 = longestHorzLines[minIndex][3];
    line(frame, Point(x1, y1), Point(x2, y2), Scalar(0,0,255), 3, 8 );


    // for( size_t i = 0; i < newlines.size(); i++ ) {
    //     line(cdst, Point(newlines[i][0], newlines[i][1]), Point(newlines[i][2], newlines[i][3]), Scalar(0,255,0), 1, 8 );
    // }

    imshow("detected lines", cdst);
}

double findSlope(int x1, int y1, int x2, int y2) {
    //cout << "" int x1, int y1, int x2, int y2;
    int dx = x2 - x1;
    int dy = y2 - y1;
	if (dx == 0) // dy doesnt matter
		return 999;
    else
        return dy / dx;
}
double findDistance(int x1, int y1, int x2, int y2) {
    int distancex = (x2 - x1)^2;
    int distancey = (y2 - y1)^2;

    double calcdistance = sqrt(distancex - distancey);
    return calcdistance;
}
